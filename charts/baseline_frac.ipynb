{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d14055da-3152-404b-a20d-426a3f7360d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/laurasisson/odor-pair'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99fcce54-67cb-4c43-bccf-2757c0fd3c42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 43992, 'test': 39554, 'covered_notes': 77}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(\"dataset/single_fold.json\") as f:\n",
    "    split_data = json.load(f)\n",
    "{k:len(v) for k, v in split_data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66bb801a-e9b3-49a6-b73f-f82705b9225d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import analysis.fingerprint\n",
    "\n",
    "mfpgen = analysis.fingerprint.make_mfpgen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da0248dc-776f-4e0b-a017-ce476ca66c96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1471, 1468)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mols = set()\n",
    "for d in split_data[\"train\"]:\n",
    "    train_mols.update(d[\"edge\"])\n",
    "\n",
    "test_mols = set()\n",
    "for d in split_data[\"test\"]:\n",
    "    test_mols.update(d[\"edge\"])\n",
    "\n",
    "len(train_mols), len(test_mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45bace94-b912-4b90-ac7f-6008e61bb82a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert len(train_mols.intersection(test_mols)) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2f3cda3-2e42-4354-bd65-14c54ffe9f8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0884bae956304dc184857a6fa58c70b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2939 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(C)C1=CN=CC(=N1)OC.CC(C)C1=CN=C(C=N1)OC.CC(C)C1=NC=CN=C1OC\n",
      "CC(=O)c1ccc(C)n1\n",
      "InChI=1/C7H8S/c1-6-4-2-3-5-7(6)8/h2-5,8H,1H3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10:42:16] SMILES Parse Error: syntax error while parsing: (C)C1=CN=CC(=N1)OC.CC(C)C1=CN=C(C=N1)OC.CC(C)C1=NC=CN=C1OC\n",
      "[10:42:16] SMILES Parse Error: Failed parsing SMILES '(C)C1=CN=CC(=N1)OC.CC(C)C1=CN=C(C=N1)OC.CC(C)C1=NC=CN=C1OC' for input: '(C)C1=CN=CC(=N1)OC.CC(C)C1=CN=C(C=N1)OC.CC(C)C1=NC=CN=C1OC'\n",
      "[10:42:16] Can't kekulize mol.  Unkekulized atoms: 3 4 5 6 8\n",
      "[10:42:16] SMILES Parse Error: syntax error while parsing: InChI=1/C7H8S/c1-6-4-2-3-5-7(6)8/h2-5,8H,1H3\n",
      "[10:42:16] SMILES Parse Error: Failed parsing SMILES 'InChI=1/C7H8S/c1-6-4-2-3-5-7(6)8/h2-5,8H,1H3' for input: 'InChI=1/C7H8S/c1-6-4-2-3-5-7(6)8/h2-5,8H,1H3'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('C[C@@H](CCC=C(C)C)C1CCC(=C)C=C1',\n",
       " array([0, 1, 0, ..., 0, 0, 0], dtype=uint8))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "mol_to_embed = dict()\n",
    "for m in tqdm(train_mols.union(test_mols)):\n",
    "    try:\n",
    "        mol_to_embed[m] = analysis.fingerprint.smiles_to_embed(mfpgen,m)\n",
    "    except Exception as e:\n",
    "        print(m)\n",
    "        continue\n",
    "        \n",
    "    \n",
    "next(iter(mol_to_embed.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "745299d6-cb4d-45d8-b671-98efc618a80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_blend_notes = {'oily', 'ethereal', 'fermented', 'bitter', 'soapy', 'phenolic', 'winey', 'roasted', 'spicy', 'fusel', 'tropical', 'anise', 'honey', 'aromatic', 'meaty', 'fresh', 'woody', 'melon', 'mentholic', 'clean', 'camphoreous', 'nutty', 'herbal', 'jammy', 'earthy', 'vegetable', 'caramellic', 'coconut', 'orris', 'bready', 'citrus', 'chemical', 'burnt', 'dairy', 'cheesy', 'fatty', 'floral', 'fruity', 'green', 'marine', 'coumarinic', 'licorice', 'mossy', 'tonka', 'creamy', 'waxy', 'animal', 'acidic', 'brown', 'cocoa', 'chocolate', 'sweet', 'rummy', 'sour', 'balsamic', 'coffee', 'solvent', 'fungal', 'berry', 'amber', 'cooling', 'onion', 'buttery', 'estery', 'powdery', 'musk', 'aldehydic', 'medicinal', 'alliaceous', 'minty', 'vanilla', 'thujonic', 'sulfurous', 'musty'}\n",
    "all_blend_notes = list(all_blend_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b12b3cf-de32-4219-9e14-eb967a4c5d87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9267532ba2fe40e9ace10a669d06a420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43992 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 262 empty blends.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac3cbb8611b45b3ae0805c1041e5d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39554 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 286 empty blends.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((43721, 4096), (39237, 4096), (43721, 74), (39237, 74))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import graph.utils\n",
    "\n",
    "def make_notes_vectors(dataset,should_concat=True):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    empty = 0\n",
    "    for d in tqdm(dataset):\n",
    "        blnd = graph.utils.canonize(d[\"blend_notes\"])\n",
    "        \n",
    "        mol1, mol2 = d[\"edge\"]\n",
    "        if not mol1 in mol_to_embed or not mol2 in mol_to_embed:\n",
    "            continue\n",
    "        \n",
    "        if should_concat:\n",
    "            x = np.concatenate([mol_to_embed[mol1],mol_to_embed[mol2]])\n",
    "        else:\n",
    "            x = mol_to_embed[mol1] + mol_to_embed[mol2]\n",
    "        y = graph.utils.multi_hot(blnd,all_blend_notes)\n",
    "\n",
    "        if x.sum() == 0 or y.sum() == 0:\n",
    "            empty += 1\n",
    "            continue\n",
    "\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        \n",
    "    print(f\"Found {empty} empty blends.\")        \n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "train_x, train_y = make_notes_vectors(split_data[\"train\"])\n",
    "test_x, test_y = make_notes_vectors(split_data[\"test\"])\n",
    "train_x.shape, test_x.shape, train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0937bba2-f67d-433f-80c1-d057afe9a5fa",
   "metadata": {},
   "source": [
    "### Using concatenation of MFPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42e315d5-8105-4c59-9d00-e94cd793c84b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data looks good!'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def checksum(vector):\n",
    "    # Assert every label has a sample and Assert every sample has a label\n",
    "    return (vector.sum(axis=0) > 0).all() and (vector.sum(axis=1) > 0).all()\n",
    "assert checksum(train_y)\n",
    "assert checksum(test_y)\n",
    "\"Data looks good!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f5f65e-b140-4773-b222-a382d73c2f75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593905e8ebcc408184d72fc0d68b70f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 macro AUROC: 0.7603564314714192\n",
      "0.30000000000000004 macro AUROC: 0.7635943275822386\n",
      "0.4 macro AUROC: 0.7613288908796166\n",
      "0.5 macro AUROC: 0.754887285791242\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "import sklearn.ensemble\n",
    "import sklearn.linear_model\n",
    "import random\n",
    "\n",
    "def train_evaluate_model_clf(base_classifier, fraction=1):\n",
    "    # Hack because I want progress bars\n",
    "    estimators = []\n",
    "    frac_idcs = random.sample(list(range(len(train_x))),int(fraction*len(train_x)))\n",
    "    frac_x, frac_y = train_x[frac_idcs], train_y[frac_idcs]\n",
    "    \n",
    "    for i in tqdm(range(train_y.shape[1]), desc=\"Training classifiers for each label\",disable=True):\n",
    "        classifier = sklearn.base.clone(base_classifier) \n",
    "        estimators.append(classifier.fit(frac_x, frac_y[:, i]))\n",
    "        \n",
    "    test_pred = np.zeros_like(test_y, dtype=float)\n",
    "    for i in range(test_y.shape[1]):\n",
    "        test_pred[:, i] = estimators[i].predict_proba(test_x)[:,1]\n",
    "    \n",
    "    # Calculate AUROC for micro and macro averaging\n",
    "    for average in ['macro']:\n",
    "        auroc = sklearn.metrics.roc_auc_score(test_y, test_pred, average=average)\n",
    "        print(frac,average,\"AUROC:\", auroc)\n",
    "        \n",
    "    auroc_per_label = {}\n",
    "    for i, label in enumerate(all_blend_notes):\n",
    "        auroc = sklearn.metrics.roc_auc_score(test_y[:, i], test_pred[:, i])\n",
    "        auroc_per_label[label] = auroc\n",
    "    \n",
    "    # return auroc_per_label\n",
    "    \n",
    "for frac in tqdm(np.linspace(.1, 1, 10),smoothing=0):\n",
    "    try:\n",
    "        train_evaluate_model_clf(sklearn.linear_model.LogisticRegression(max_iter=1000),frac)\n",
    "    except ValueError as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c118a516-3fea-43d7-a276-7c8a6e2fc9dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Predicting probabilities for AUROC calculation...\n",
      "Sklearn Macro-averaged AUROC: 0.49064521690036866\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "\n",
    "class LogitRegression:\n",
    "    EPS = 1e-5\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def _clip01(self, arr):\n",
    "        return np.asarray(arr).clip(self.EPS, 1 - self.EPS)\n",
    "\n",
    "    def fit(self, x, p):\n",
    "        p = self._clip01(p)\n",
    "        y = scipy.special.logit(p)\n",
    "        return self.model.fit(x, y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        y = self.model.predict(x)\n",
    "        return scipy.special.expit(y)\n",
    "\n",
    "def train_evaluate_model_logit(base_classifier):\n",
    "    print(\"Training the model...\")\n",
    "    model = LogitRegression(base_classifier)\n",
    "    model.fit(train_x, train_y)\n",
    "\n",
    "    print(\"Predicting probabilities for AUROC calculation...\")\n",
    "    test_pred = model.predict(test_x)\n",
    "\n",
    "     # Calculate AUROC using sklearn\n",
    "    auc_micro_sklearn = sklearn.metrics.roc_auc_score(test_y, test_pred, average='micro')\n",
    "    auc_macro_sklearn = sklearn.metrics.roc_auc_score(test_y, test_pred, average='macro')\n",
    "\n",
    "    # print(\"Sklearn Micro-averaged AUROC:\", auc_micro_sklearn)\n",
    "    print(\"Sklearn Macro-averaged AUROC:\", auc_macro_sklearn)\n",
    "    \n",
    "    auroc_per_label = {}\n",
    "    for i, label in enumerate(all_blend_notes):\n",
    "        auroc = sklearn.metrics.roc_auc_score(test_y[:, i], test_pred[:, i])\n",
    "        auroc_per_label[label] = auroc\n",
    "    \n",
    "    # return auroc_per_label\n",
    "    \n",
    "train_evaluate_model_logit(sklearn.linear_model.LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70171903-d84a-4d92-a5f9-76c66f8c2657",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb902d76058e40ad888387fc4466c08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43992 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 262 empty blends.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f70861ecac43479f8b616a42645b34f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39554 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 286 empty blends.\n",
      "(43721, 2048) (39237, 2048) (43721, 74) (39237, 74)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Data looks good!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, train_y = make_notes_vectors(split_data[\"train\"],should_concat=False)\n",
    "test_x, test_y = make_notes_vectors(split_data[\"test\"],should_concat=False)\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)\n",
    "assert checksum(train_y)\n",
    "assert checksum(test_y)\n",
    "\"Data looks good!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe23e498-02e0-4fc1-a6eb-8ff3c71a7f70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Training the model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e609f9075d04a7d9cb882c315a1b92e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training classifiers for each label:   0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting probabilities for AUROC calculation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375289bb19eb4536af4c6009437d4cb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting probabilities:   0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro AUROC: 0.7392836214911928\n",
      "Linear Regression\n",
      "Training the model...\n",
      "Predicting probabilities for AUROC calculation...\n",
      "Sklearn Macro-averaged AUROC: 0.49414529054634415\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression\")\n",
    "train_evaluate_model_clf(sklearn.linear_model.LogisticRegression(max_iter=1000))\n",
    "print(\"Linear Regression\")\n",
    "train_evaluate_model_logit(sklearn.linear_model.LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53a789ee-a353-4880-b2b1-91b43e7cbbc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import sklearn.ensemble\n",
    "\n",
    "# print(\"Random Forest\")\n",
    "# train_evaluate_model(sklearn.ensemble.RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7da2da0b-745b-4d77-ba12-59fe64a35173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import sklearn.svm\n",
    "# import sklearn.multioutput\n",
    "\n",
    "# print(\"SVM\")\n",
    "# train_evaluate_model(sklearn.svm.SVC(probability=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc8625a-6c53-4acb-9a51-9f2846d082a5",
   "metadata": {},
   "source": [
    "### Using summation of MFPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7569b64d-4bd6-4786-8fc0-2bab9b9c980d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_x, train_y = make_notes_vectors(split_data[\"train\"],split_data[\"covered_notes\"],should_concat=False)\n",
    "# test_x, test_y = make_notes_vectors(split_data[\"test\"],split_data[\"covered_notes\"],should_concat=False)\n",
    "# print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)\n",
    "# assert checksum(train_y)\n",
    "# assert checksum(test_y)\n",
    "# \"Data looks good!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d52c5f71-b7dd-49a6-918b-2079d12c426c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(\"Logistic Regression\")\n",
    "# train_evaluate_model(sklearn.linear_model.LinearRegression())\n",
    "# print()\n",
    "# print(\"Random Forest\")\n",
    "# train_evaluate_model(sklearn.ensemble.RandomForestClassifier())\n",
    "# print()\n",
    "# print(\"SVM\")\n",
    "# train_evaluate_model(sklearn.svm.SVC(probability=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
