{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cc5fab7-aedf-4812-8f6d-4bb8744d880f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/laurasisson/odor-pair'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d4b5619-9864-457f-bf6d-956e70123abe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166814,\n",
       " {'mol1': 'CCCCC/C=C/C(=O)OC',\n",
       "  'mol1_notes': ['violet',\n",
       "   'sweet',\n",
       "   'oily',\n",
       "   'melon',\n",
       "   'pear',\n",
       "   'hairy',\n",
       "   'costus',\n",
       "   'fruity',\n",
       "   'violet leaf',\n",
       "   'waxy',\n",
       "   'fresh',\n",
       "   'green'],\n",
       "  'mol2': 'CCCCCOC(=O)CCC',\n",
       "  'mol2_notes': ['cherry',\n",
       "   'sweet',\n",
       "   'pineapple',\n",
       "   'fruity',\n",
       "   'banana',\n",
       "   'tropical'],\n",
       "  'blend_notes': ['animal', 'fruity', 'waxy']})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(\"dataset/full.json\") as f:\n",
    "    full_data = json.load(f)\n",
    "len(full_data), full_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3c5d86eb-d122-49b2-aa84-3083e5e3983f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2971"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "mol_to_notes = dict()\n",
    "for d in full_data:\n",
    "    mol_to_notes[d[\"mol1\"]] = d[\"mol1_notes\"]\n",
    "    mol_to_notes[d[\"mol2\"]] = d[\"mol2_notes\"]    \n",
    "len(mol_to_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcddf6bb-59bb-4e60-a769-a08bb35152ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Before Canonicalization: |Single Notes| = 398. After Canonicalization: |Single Notes| = 398.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import single.utils\n",
    "import graph.utils\n",
    "\n",
    "raw_single_notes = set()\n",
    "for d in data:\n",
    "    raw_single_notes.update(d[\"mol1_notes\"])\n",
    "    raw_single_notes.update(d[\"mol2_notes\"])\n",
    "\n",
    "all_single_notes = list(single.utils.canonize(raw_single_notes))\n",
    "f\"Before Canonicalization: |Single Notes| = {len(all_single_notes)}. After Canonicalization: |Single Notes| = {len(all_single_notes)}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "889b51b0-cce0-4642-b4b3-b75787ebfe38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 43992, 'test': 39554, 'covered_notes': 77}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(\"dataset/single_fold.json\") as f:\n",
    "    split_data = json.load(f)\n",
    "{k:len(v) for k, v in split_data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc228596-3cec-4da9-9cdc-bd01c0b5fb41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edge': ['CCCCCCCCCCCC(OC)OC', 'CCC/C=C\\\\CO'], 'blend_notes': ['green']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_data[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2e7c8e27-f1e7-459f-9d56-bc0b5705ff75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(361, 369, 332)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_seen_single_notes(dataset):\n",
    "    seen = set()\n",
    "    for d in dataset:\n",
    "        mol1, mol2 = d[\"edge\"]\n",
    "        seen.update(mol_to_notes[mol1])\n",
    "        seen.update(mol_to_notes[mol2])\n",
    "    return set(single.utils.canonize(seen))\n",
    "train_singles = get_seen_single_notes(split_data[\"train\"])\n",
    "test_singles = get_seen_single_notes(split_data[\"test\"])\n",
    "common_singles = train_singles.intersection(test_singles)\n",
    "len(train_singles), len(test_singles), len(common_singles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c422e8b7-2c7f-4719-ac40-66394c6029d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6008b0d9dd174de3b257ec3a0e589182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43992 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'set' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mempty\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m empty blends.\u001b[39m\u001b[38;5;124m\"\u001b[39m)        \n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(xs), np\u001b[38;5;241m.\u001b[39marray(ys)\n\u001b[0;32m---> 27\u001b[0m train_x, train_y \u001b[38;5;241m=\u001b[39m make_notes_vectors(split_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m],split_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcovered_notes\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     28\u001b[0m test_x, test_y \u001b[38;5;241m=\u001b[39m make_notes_vectors(split_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m],split_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcovered_notes\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     29\u001b[0m train_x\u001b[38;5;241m.\u001b[39mshape, test_x\u001b[38;5;241m.\u001b[39mshape, train_y\u001b[38;5;241m.\u001b[39mshape, test_y\u001b[38;5;241m.\u001b[39mshape\n",
      "Cell \u001b[0;32mIn[61], line 14\u001b[0m, in \u001b[0;36mmake_notes_vectors\u001b[0;34m(dataset, all_blend_notes)\u001b[0m\n\u001b[1;32m     11\u001b[0m n1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(single\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcanonize(mol_to_notes[mol1]))\n\u001b[1;32m     12\u001b[0m n2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(single\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcanonize(mol_to_notes[mol2]))\n\u001b[0;32m---> 14\u001b[0m x \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mmulti_hot(n1,common_singles)\u001b[38;5;241m+\u001b[39mgraph\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mmulti_hot(n2,common_singles)\n\u001b[1;32m     15\u001b[0m y \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mmulti_hot(blnd,all_blend_notes)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/odor-pair/graph/utils.py:46\u001b[0m, in \u001b[0;36mmulti_hot\u001b[0;34m(notes, underyling_list, should_canonize)\u001b[0m\n\u001b[1;32m     44\u001b[0m     underyling_list \u001b[38;5;241m=\u001b[39m CANON_NOTES_LIST\n\u001b[1;32m     45\u001b[0m notes \u001b[38;5;241m=\u001b[39m [n \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m notes \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m underyling_list]\n\u001b[0;32m---> 46\u001b[0m indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([underyling_list\u001b[38;5;241m.\u001b[39mindex(n) \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m notes])\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(indices) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(underyling_list))\n",
      "File \u001b[0;32m~/odor-pair/graph/utils.py:46\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m     underyling_list \u001b[38;5;241m=\u001b[39m CANON_NOTES_LIST\n\u001b[1;32m     45\u001b[0m notes \u001b[38;5;241m=\u001b[39m [n \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m notes \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m underyling_list]\n\u001b[0;32m---> 46\u001b[0m indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([underyling_list\u001b[38;5;241m.\u001b[39mindex(n) \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m notes])\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(indices) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(underyling_list))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'set' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_notes_vectors(dataset,all_blend_notes):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    empty = 0\n",
    "    for d in tqdm(dataset):\n",
    "        blnd = graph.utils.canonize(d[\"blend_notes\"])\n",
    "        \n",
    "        mol1, mol2 = d[\"edge\"]\n",
    "        n1 = set(single.utils.canonize(mol_to_notes[mol1]))\n",
    "        n2 = set(single.utils.canonize(mol_to_notes[mol2]))\n",
    "        \n",
    "        x = graph.utils.multi_hot(n1,common_singles)+graph.utils.multi_hot(n2,common_singles)\n",
    "        y = graph.utils.multi_hot(blnd,all_blend_notes)\n",
    "\n",
    "        if x.sum() == 0 or y.sum() == 0:\n",
    "            empty += 1\n",
    "            continue\n",
    "\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        \n",
    "    print(f\"Found {empty} empty blends.\")        \n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "train_x, train_y = make_notes_vectors(split_data[\"train\"],split_data[\"covered_notes\"])\n",
    "test_x, test_y = make_notes_vectors(split_data[\"test\"],split_data[\"covered_notes\"])\n",
    "train_x.shape, test_x.shape, train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3f9c7242-d584-43fb-963e-0dc3a72d7775",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Assert every sample has a label\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (vector\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m----> 6\u001b[0m checksum(train_x), checksum(train_y)\n",
      "Cell \u001b[0;32mIn[55], line 3\u001b[0m, in \u001b[0;36mchecksum\u001b[0;34m(vector)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchecksum\u001b[39m(vector):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Assert every label has a sample\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (vector\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Assert every sample has a label\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (vector\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mall()\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def checksum(vector):\n",
    "    # Assert every label has a sample\n",
    "    assert (vector.sum(axis=0) > 0).all()\n",
    "    # Assert every sample has a label\n",
    "    assert (vector.sum(axis=1) > 0).all()\n",
    "checksum(train_x), checksum(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ff4af17-ed82-4ec5-ae2a-ee24ed675299",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_x, train_y = train_x[:15000,:], train_y[:15000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7cbee95e-aea9-4835-b37e-e6001960a8e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert (train_x.sum(axis=-1) > 0).all() and (test_x > 0).sum(axis=-1).all() and (train_y.sum(axis=-1) > 0).all() and (test_y.sum(axis=-1) > 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "86446ed1-edc8-4a26-b1c5-bed4548db830",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2085efa0822c4ad9848727280894bec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training classifiers for each label:   0%|          | 0/77 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Hack because I want progress bars\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(train_y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining classifiers for each label\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 13\u001b[0m     models\u001b[38;5;241m.\u001b[39mappend( [base_clf\u001b[38;5;241m.\u001b[39mfit(train_x, train_y[:, i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(train_y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])])\n",
      "Cell \u001b[0;32mIn[40], line 13\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Hack because I want progress bars\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(train_y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining classifiers for each label\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 13\u001b[0m     models\u001b[38;5;241m.\u001b[39mappend( [base_clf\u001b[38;5;241m.\u001b[39mfit(train_x, train_y[:, i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(train_y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])])\n",
      "File \u001b[0;32m~/miniconda3/envs/rdenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1239\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 1241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1245\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1246\u001b[0m     )\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1249\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0"
     ]
    }
   ],
   "source": [
    "import sklearn.linear_model\n",
    "import sklearn.multiclass\n",
    "\n",
    "base_clf = sklearn.linear_model.LogisticRegression(max_iter=1000)\n",
    "# model = sklearn.multiclass.OneVsRestClassifier(base_clf)\n",
    "# model.fit(train_x,train_y)\n",
    "# test_pred = model.predict(test_x)\n",
    "models = []\n",
    "\n",
    "print(\"Training the model...\")\n",
    "# Hack because I want progress bars\n",
    "for i in tqdm(range(train_y.shape[1]), desc=\"Training classifiers for each label\"):\n",
    "    models.append( [base_clf.fit(train_x, train_y[:, i]) for i in range(train_y.shape[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f4dd5d-18bb-4367-9058-990e64510943",
   "metadata": {},
   "source": [
    "Ok so\n",
    "* Build the training data from single_notes -> pair_notes\n",
    "* train linear model / random forest model to predict.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
