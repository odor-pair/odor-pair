{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a28255c-ed13-4204-b92d-c49b83279ce9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/laurasisson/odor-pair'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2043fec9-0034-4022-bc50-11dff4d77e0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166814,\n",
       " {'mol1': 'CCCCC/C=C/C(=O)OC',\n",
       "  'mol1_notes': ['violet',\n",
       "   'sweet',\n",
       "   'oily',\n",
       "   'melon',\n",
       "   'pear',\n",
       "   'hairy',\n",
       "   'costus',\n",
       "   'fruity',\n",
       "   'violet leaf',\n",
       "   'waxy',\n",
       "   'fresh',\n",
       "   'green'],\n",
       "  'mol2': 'CCCCCOC(=O)CCC',\n",
       "  'mol2_notes': ['cherry',\n",
       "   'sweet',\n",
       "   'pineapple',\n",
       "   'fruity',\n",
       "   'banana',\n",
       "   'tropical'],\n",
       "  'blend_notes': ['animal', 'fruity', 'waxy']})"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(\"dataset/full.json\") as f:\n",
    "    data = json.load(f)\n",
    "len(data), data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "710cc251-2eec-4eac-8c13-48aa5c739cac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Before Canonicalization: |Blend Notes| = 109. |Single Notes| = 496'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graph.utils\n",
    "import single.utils\n",
    "\n",
    "all_blend_notes = set()\n",
    "all_single_notes = set()\n",
    "for d in data:\n",
    "    all_blend_notes.update(d[\"blend_notes\"])\n",
    "    all_single_notes.update(d[\"mol1_notes\"])\n",
    "    all_single_notes.update(d[\"mol2_notes\"])\n",
    "\n",
    "f\"Before Canonicalization: |Blend Notes| = {len(all_blend_notes)}. |Single Notes| = {len(all_single_notes)}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f6f7832c-a387-4e25-aa62-1f95aa62e0e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'After Canonicalization: |Blend Notes| = 104. |Single Notes| = 398.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_blend_notes = list(graph.utils.canonize(all_blend_notes))\n",
    "all_single_notes = list(single.utils.canonize(all_single_notes))\n",
    "    \n",
    "f\"After Canonicalization: |Blend Notes| = {len(all_blend_notes)}. |Single Notes| = {len(all_single_notes)}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "136aa2c4-7414-4105-afdb-72393b9051de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The following notes appear only in blends: {'anise', 'minty'}.\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"The following notes appear only in blends: {set(all_blend_notes).difference(set(all_single_notes))}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f9adc7bf-32aa-47bd-bd3f-9614b688b61a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Found a total of 400 notes.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_notes = set(all_blend_notes).union(set(all_single_notes))\n",
    "f\"Found a total of {len(all_notes)} notes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9df70dc8-58ca-44c7-b2e6-da9568946b8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Found a total of 102 notes in common.'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_notes = set(all_blend_notes).intersection(set(all_single_notes))\n",
    "f\"Found a total of {len(common_notes)} notes in common.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57bff59f-fc04-470c-95cb-0055019672c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ad82c2833c4e98ab88cce77a439fd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/166814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unions = []\n",
    "intersections = []\n",
    "blends = []\n",
    "for d in tqdm(data):\n",
    "    blnd = set(graph.utils.canonize(d[\"blend_notes\"]))\n",
    "    if not blnd:\n",
    "        continue\n",
    "\n",
    "    n1 = set(single.utils.canonize(d[\"mol1_notes\"]))\n",
    "    n2 = set(single.utils.canonize(d[\"mol2_notes\"]))\n",
    "    \n",
    "    unions.append(n1.union(n2))\n",
    "    intersections.append(n1.intersection(n2))\n",
    "    blends.append(blnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7ebd9768-3e32-46b6-979a-aef457b27475",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2168ca0bb4854365989e1ff51cae8bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/166542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Score (Union): 0.20076464784185133\n",
      "Average F1 Score (Intersection): 0.34769725783076694\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize empty lists to hold all vectors\n",
    "all_union_vectors = []\n",
    "all_intersection_vectors = []\n",
    "all_blend_vectors = []\n",
    "\n",
    "for union, intersection, blend in tqdm(zip(unions, intersections, blends), total=len(blends)):\n",
    "    # Convert sets to binary vectors over the universe of notes (all_notes)\n",
    "    union_vector = [int(note in union) for note in all_notes]\n",
    "    intersection_vector = [int(note in intersection) for note in all_notes]\n",
    "    blend_vector = [int(note in blend) for note in all_notes]\n",
    "    \n",
    "    # Append the vectors for bulk calculation\n",
    "    all_union_vectors.extend(union_vector)\n",
    "    all_intersection_vectors.extend(intersection_vector)\n",
    "    all_blend_vectors.extend(blend_vector)\n",
    "\n",
    "# Convert the lists to numpy arrays for bulk F1 score calculation\n",
    "all_union_vectors = np.array(all_union_vectors)\n",
    "all_intersection_vectors = np.array(all_intersection_vectors)\n",
    "all_blend_vectors = np.array(all_blend_vectors)\n",
    "\n",
    "# Calculate F1 scores in bulk\n",
    "f1_union_avg = f1_score(all_blend_vectors, all_union_vectors)\n",
    "f1_intersection_avg = f1_score(all_blend_vectors, all_intersection_vectors)\n",
    "\n",
    "print(\"Average F1 Score (Union):\", f1_union_avg)\n",
    "print(\"Average F1 Score (Intersection):\", f1_intersection_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "05b1b1f2-f63b-43e9-8a5c-84dead349dc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Example: Single notes = {'fruity', 'sweet'}. Pair notes = {'fruity', 'animal', 'waxy'}. Emergent notes = {'animal', 'waxy'}. Suppressed note = {'sweet'}.\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emergences = []\n",
    "suppressions = []\n",
    "\n",
    "for intersection, blend in zip(intersections,blends):\n",
    "    emergences.append(blend.difference(intersection))\n",
    "    suppressions.append(intersection.difference(blend))\n",
    "    \n",
    "f\"Example: Single notes = {intersections[0]}. Pair notes = {blends[0]}. Emergent notes = {emergences[0]}. Suppressed note = {suppressions[0]}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f5ea5120-2b16-4992-8b05-1a827152b518",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For the average blend, we get = 0.89 new notes, and lose 1.17 notes.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    f\"For the average blend, we get = {np.mean([len(x) for x in emergences]):.2f} new notes, and lose {np.mean([len(x) for x in suppressions]):.2f} notes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f4c666b3-8063-4137-9bf9-d9f7276c14ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Likely to Emerge:\n",
      "aromatic: 1.0000\n",
      "mushroom: 1.0000\n",
      "juicy: 1.0000\n",
      "potato: 1.0000\n",
      "malty: 1.0000\n",
      "eggy: 1.0000\n",
      "fresh: 1.0000\n",
      "cabbage: 1.0000\n",
      "celery: 1.0000\n",
      "acetic: 1.0000\n",
      "salty: 1.0000\n",
      "pine: 1.0000\n",
      "hay: 1.0000\n",
      "medicinal: 0.9942\n",
      "mossy: 0.9912\n",
      "moldy: 0.9905\n",
      "chemical: 0.9900\n",
      "burnt: 0.9789\n",
      "solvent: 0.9785\n",
      "marine: 0.9732\n",
      "fungal: 0.9711\n",
      "estery: 0.9702\n",
      "dairy: 0.9688\n",
      "toasted: 0.9679\n",
      "mustard: 0.9649\n",
      "\n",
      "Most Likely to be Suppressed:\n",
      "mushroom: 1.0000\n",
      "fresh: 1.0000\n",
      "pine: 1.0000\n",
      "juicy: 1.0000\n",
      "potato: 1.0000\n",
      "cabbage: 1.0000\n",
      "celery: 1.0000\n",
      "aromatic: 1.0000\n",
      "hay: 1.0000\n",
      "eggy: 1.0000\n",
      "malty: 1.0000\n",
      "acetic: 1.0000\n",
      "sweet: 0.9994\n",
      "peach: 0.9883\n",
      "powdery: 0.9859\n",
      "clean: 0.9773\n",
      "cherry: 0.9764\n",
      "dairy: 0.9679\n",
      "oily: 0.9628\n",
      "pungent: 0.9605\n",
      "burnt: 0.9540\n",
      "rooty: 0.9483\n",
      "garlic: 0.9474\n",
      "dusty: 0.9429\n",
      "medicinal: 0.9398\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Step 1: Calculate baseline frequency of notes in individual molecules\n",
    "baseline_individual_freq = Counter(note for intersection in intersections for note in intersection)\n",
    "\n",
    "# Step 2: Calculate baseline frequency of notes in blends\n",
    "baseline_blend_freq = Counter(note for blend in blends for note in blend)\n",
    "\n",
    "# Step 3: Calculate raw frequency of emergent and suppressed notes\n",
    "emergence_freq = Counter(note for emerg in emergences for note in emerg if note in common_notes)\n",
    "suppression_freq = Counter(note for supp in suppressions for note in supp if note in common_notes)\n",
    "\n",
    "# Step 4: Normalize emergences by blend frequencies\n",
    "normalized_emergence = Counter({note: (emergence_freq[note] / baseline_blend_freq[note])\n",
    "                               for note in emergence_freq if baseline_blend_freq[note] > 0})\n",
    "\n",
    "# Step 5: Normalize suppressions by individual frequencies\n",
    "normalized_suppression = Counter({note: (suppression_freq[note] / baseline_individual_freq[note])\n",
    "                                 for note in suppression_freq if baseline_individual_freq[note] > 0})\n",
    "\n",
    "\n",
    "# Step 6: Get the top 10 most likely to emerge and be suppressed\n",
    "top_10_emergent_notes = normalized_emergence.most_common(25)\n",
    "top_10_suppressed_notes = normalized_suppression.most_common(25)\n",
    "\n",
    "# Step 7: Print results\n",
    "print(\"Most Likely to Emerge:\")\n",
    "for note, score in top_10_emergent_notes:\n",
    "    print(f\"{note}: {score:.4f}\")\n",
    "print()\n",
    "print(\"Most Likely to be Suppressed:\")\n",
    "for note, score in top_10_suppressed_notes:\n",
    "    print(f\"{note}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7e909c0d-f746-408e-914f-058f6c41b412",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least Likely to Emerge:\n",
      "peach: 0.1000\n",
      "garlic: 0.3506\n",
      "meaty: 0.3735\n",
      "fruity: 0.3923\n",
      "green: 0.4337\n",
      "lactonic: 0.5000\n",
      "woody: 0.5358\n",
      "musk: 0.5469\n",
      "onion: 0.5503\n",
      "coconut: 0.6190\n",
      "\n",
      "Least Likely to be Suppressed:\n",
      "alliaceous: 0.3212\n",
      "floral: 0.3407\n",
      "fruity: 0.4041\n",
      "musk: 0.4687\n",
      "vanilla: 0.4840\n",
      "aldehydic: 0.4886\n",
      "caramellic: 0.4891\n",
      "sulfurous: 0.4920\n",
      "tarragon: 0.5000\n",
      "tonka: 0.5305\n"
     ]
    }
   ],
   "source": [
    "top_10_emergent_notes = reversed(normalized_emergence.most_common()[-10:])\n",
    "top_10_suppressed_notes = reversed(normalized_suppression.most_common()[-10:])\n",
    "\n",
    "print(\"Least Likely to Emerge:\")\n",
    "for note, score in top_10_emergent_notes:\n",
    "    print(f\"{note}: {score:.4f}\")\n",
    "print()\n",
    "print(\"Least Likely to be Suppressed:\")\n",
    "for note, score in top_10_suppressed_notes:\n",
    "    print(f\"{note}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "47c908d3-31e1-43d3-9e95-fd2389d42eb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Note</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Normalized Emergence</th>\n",
       "      <th>Normalized Suppression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fruity</td>\n",
       "      <td>50409</td>\n",
       "      <td>0.392271</td>\n",
       "      <td>0.404081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>floral</td>\n",
       "      <td>47627</td>\n",
       "      <td>0.619187</td>\n",
       "      <td>0.340712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>green</td>\n",
       "      <td>29375</td>\n",
       "      <td>0.433668</td>\n",
       "      <td>0.621858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>waxy</td>\n",
       "      <td>11092</td>\n",
       "      <td>0.701316</td>\n",
       "      <td>0.641567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>herbal</td>\n",
       "      <td>9157</td>\n",
       "      <td>0.680245</td>\n",
       "      <td>0.632207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>woody</td>\n",
       "      <td>8707</td>\n",
       "      <td>0.535776</td>\n",
       "      <td>0.625290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>balsamic</td>\n",
       "      <td>7047</td>\n",
       "      <td>0.838655</td>\n",
       "      <td>0.585339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>citrus</td>\n",
       "      <td>5544</td>\n",
       "      <td>0.795635</td>\n",
       "      <td>0.702468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spicy</td>\n",
       "      <td>5291</td>\n",
       "      <td>0.736912</td>\n",
       "      <td>0.634166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fatty</td>\n",
       "      <td>4679</td>\n",
       "      <td>0.785211</td>\n",
       "      <td>0.765843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Note  Frequency  Normalized Emergence  Normalized Suppression\n",
       "0    fruity      50409              0.392271                0.404081\n",
       "1    floral      47627              0.619187                0.340712\n",
       "2     green      29375              0.433668                0.621858\n",
       "3      waxy      11092              0.701316                0.641567\n",
       "4    herbal       9157              0.680245                0.632207\n",
       "5     woody       8707              0.535776                0.625290\n",
       "6  balsamic       7047              0.838655                0.585339\n",
       "7    citrus       5544              0.795635                0.702468\n",
       "8     spicy       5291              0.736912                0.634166\n",
       "9     fatty       4679              0.785211                0.765843"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_data = []\n",
    "for note in common_notes:\n",
    "    csv_data.append({\n",
    "        'Note': note,\n",
    "        'Frequency': baseline_blend_freq.get(note, 0),\n",
    "        'Normalized Emergence': normalized_emergence.get(note, 0),\n",
    "        'Normalized Suppression': normalized_suppression.get(note, 0),\n",
    "    })\n",
    "\n",
    "# Step 3: Create a DataFrame and sort by `Baseline Blend Frequency`\n",
    "df = pd.DataFrame(csv_data)\n",
    "df = df.sort_values(by='Frequency', ascending=False)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Step 4: Save to CSV\n",
    "df.to_csv('charts/csv/notes_emergence_suppression.csv', index=False)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8b795768-e343-4c9d-9404-3d684e5ae91e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246334e0b5564509bb5546057762ee34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/166814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 272 empty blends and 0 self loops.\n"
     ]
    }
   ],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "empty = 0\n",
    "selfloops = 0\n",
    "\n",
    "common_notes_list = list(common_notes)\n",
    "\n",
    "for d in tqdm(data):\n",
    "    blnd = graph.utils.canonize(d[\"blend_notes\"])\n",
    "    if not blnd:\n",
    "        empty += 1\n",
    "        continue\n",
    "\n",
    "    n1 = set(single.utils.canonize(d[\"mol1_notes\"]))\n",
    "    n2 = set(single.utils.canonize(d[\"mol2_notes\"]))\n",
    "    \n",
    "    x = graph.utils.multi_hot(n1,all_single_notes)+graph.utils.multi_hot(n2,all_single_notes)\n",
    "    y = graph.utils.multi_hot(blnd,all_blend_notes)\n",
    "    \n",
    "    if x.sum() == 0 or y.sum() == 0:\n",
    "        empty += 1\n",
    "        continue\n",
    "\n",
    "    xs.append(x)\n",
    "    ys.append(y)\n",
    "\n",
    "print(f\"Found {empty} empty blends and {selfloops} self loops.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "cdb072c3-c672-4d6f-afff-79af8510cd79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for y in ys:\n",
    "    assert y.sum() > 0 and y.sum() < len(y)\n",
    "    \n",
    "for x in xs:\n",
    "    assert x.sum() > 0 and x.sum() < len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "0890a60e-615b-4bfd-866f-6ede339f6076",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((166542, 398), (166542, 104))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the data to NumPy arrays (if not already)\n",
    "import numpy as np\n",
    "X = np.array(xs)  # Intersected notes as features\n",
    "Y = np.array(ys)  # Multi-hot vector blend notes as target labels\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f2155a5b-d1d7-4eb8-a53d-b0f25c312d0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training classifiers for each label:   1%| | 1/104 [35:03<60:10:43, 2103.33s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[168], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining the model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining classifiers for each label\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 20\u001b[0m     clf\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m [base_clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train[:, i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Step 4: Predict on the test set with verbosity\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[168], line 20\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining the model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining classifiers for each label\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 20\u001b[0m     clf\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m [base_clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train[:, i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Step 4: Predict on the test set with verbosity\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rdenv/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    462\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    465\u001b[0m ]\n\u001b[1;32m    467\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[1;32m    474\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m    475\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    476\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    477\u001b[0m )(\n\u001b[1;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    479\u001b[0m         t,\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[1;32m    481\u001b[0m         X,\n\u001b[1;32m    482\u001b[0m         y,\n\u001b[1;32m    483\u001b[0m         sample_weight,\n\u001b[1;32m    484\u001b[0m         i,\n\u001b[1;32m    485\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[1;32m    486\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    487\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[1;32m    488\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[1;32m    489\u001b[0m     )\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/miniconda3/envs/rdenv/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/miniconda3/envs/rdenv/lib/python3.11/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/miniconda3/envs/rdenv/lib/python3.11/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/miniconda3/envs/rdenv/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/rdenv/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    182\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 184\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/rdenv/lib/python3.11/site-packages/sklearn/tree/_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    860\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \n\u001b[1;32m    862\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m    890\u001b[0m         X,\n\u001b[1;32m    891\u001b[0m         y,\n\u001b[1;32m    892\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    893\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/rdenv/lib/python3.11/site-packages/sklearn/tree/_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    370\u001b[0m         splitter,\n\u001b[1;32m    371\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    377\u001b[0m     )\n\u001b[0;32m--> 379\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight)\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Initialize the Random Forest Classifier\n",
    "base_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Step 3: Fit the OneVsRestClassifier with verbosity\n",
    "clf = OneVsRestClassifier(base_clf)\n",
    "\n",
    "# Adding progress tracking with tqdm for the training process\n",
    "print(\"Training the model...\")\n",
    "for i in tqdm(range(Y.shape[1]), desc=\"Training classifiers for each label\"):\n",
    "    clf.estimators_ = [base_clf.fit(X_train, y_train[:, i]) for i in range(Y.shape[1])]\n",
    "\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# Step 4: Predict on the test set with verbosity\n",
    "y_pred = np.zeros_like(y_test)\n",
    "print(\"Predicting the test set...\")\n",
    "for i in tqdm(range(Y.shape[1]), desc=\"Predicting labels\"):\n",
    "    y_pred[:, i] = clf.estimators_[i].predict(X_test)\n",
    "\n",
    "# Step 5: Calculate F1 score for multi-label classification\n",
    "f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Step 6: Predict probabilities (needed for AUROC) with verbosity\n",
    "y_pred_prob = np.zeros_like(y_test, dtype=float)\n",
    "print(\"Predicting probabilities for AUROC calculation...\")\n",
    "for i in tqdm(range(Y.shape[1]), desc=\"Predicting probabilities\"):\n",
    "    y_pred_prob[:, i] = clf.estimators_[i].predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Step 7: Calculate AUROC for micro and macro averaging\n",
    "auc_micro = roc_auc_score(y_test, y_pred_prob, average='micro')\n",
    "auc_macro = roc_auc_score(y_test, y_pred_prob, average='macro')\n",
    "\n",
    "# Step 8: Print the results\n",
    "print(\"Micro-averaged F1 Score:\", f1_micro)\n",
    "print(\"Macro-averaged F1 Score:\", f1_macro)\n",
    "print(\"Micro-averaged AUROC:\", auc_micro)\n",
    "print(\"Macro-averaged AUROC:\", auc_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "09ef2513-3137-469e-8d73-4a76d2bf9974",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laurasisson/miniconda3/envs/rdenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-averaged F1 Score: 0.7727141492882048\n",
      "Macro-averaged F1 Score: 0.6848094010220757\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[155], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Step 7: Calculate AUROC for micro and macro averaging\u001b[39;00m\n\u001b[1;32m     13\u001b[0m auc_micro \u001b[38;5;241m=\u001b[39m roc_auc_score(y_test, y_pred_prob, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m auc_macro \u001b[38;5;241m=\u001b[39m roc_auc_score(y_test, y_pred_prob, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Step 8: Print the results\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMicro-averaged AUROC:\u001b[39m\u001b[38;5;124m\"\u001b[39m, auc_micro)\n",
      "File \u001b[0;32m~/miniconda3/envs/rdenv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:580\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    573\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[1;32m    574\u001b[0m         y_true,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    577\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    578\u001b[0m     )\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[0;32m--> 580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    581\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[1;32m    582\u001b[0m         y_true,\n\u001b[1;32m    583\u001b[0m         y_score,\n\u001b[1;32m    584\u001b[0m         average,\n\u001b[1;32m    585\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    586\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/rdenv/lib/python3.11/site-packages/sklearn/metrics/_base.py:118\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    116\u001b[0m     y_true_c \u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39mtake([c], axis\u001b[38;5;241m=\u001b[39mnot_average_axis)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m    117\u001b[0m     y_score_c \u001b[38;5;241m=\u001b[39m y_score\u001b[38;5;241m.\u001b[39mtake([c], axis\u001b[38;5;241m=\u001b[39mnot_average_axis)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m--> 118\u001b[0m     score[c] \u001b[38;5;241m=\u001b[39m binary_metric(y_true_c, y_score_c, sample_weight\u001b[38;5;241m=\u001b[39mscore_weight)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Average the results\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/rdenv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:339\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Binary roc auc score.\"\"\"\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_true)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 339\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    340\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    341\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not defined in that case.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    342\u001b[0m     )\n\u001b[1;32m    344\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m roc_curve(y_true, y_score, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_fpr \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 5: Calculate F1 score for multi-label classification\n",
    "f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"Micro-averaged F1 Score:\", f1_micro)\n",
    "print(\"Macro-averaged F1 Score:\", f1_macro)\n",
    "\n",
    "# Step 6: Predict probabilities (needed for AUROC)\n",
    "# This is done per label (one classifier per label)\n",
    "y_pred_prob = clf.predict_proba(X_test)\n",
    "\n",
    "# Step 7: Calculate AUROC for micro and macro averaging\n",
    "auc_micro = roc_auc_score(y_test, y_pred_prob, average='micro')\n",
    "auc_macro = roc_auc_score(y_test, y_pred_prob, average='macro')\n",
    "\n",
    "# Step 8: Print the results\n",
    "\n",
    "print(\"Micro-averaged AUROC:\", auc_micro)\n",
    "print(\"Macro-averaged AUROC:\", auc_macro)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e7d2f7ff-be8f-45e2-9047-a3b2f25bfcef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming y_test is a NumPy array (num_samples x num_labels)\n",
    "\n",
    "# Step 1: Find indices where only one class is present across instances for each label\n",
    "single_class_indices = []\n",
    "\n",
    "# Loop over each label (column) in y_test\n",
    "for label_idx in range(y_test.shape[1]):\n",
    "    unique_classes = np.unique(y_test[:, label_idx])\n",
    "    \n",
    "    # If the label has only one unique value (either all 0's or all 1's), record the indices\n",
    "    if len(unique_classes) == 1:\n",
    "        # Store all instances (row indices) for this label where this happens\n",
    "        for instance_idx in range(y_test.shape[0]):\n",
    "            single_class_indices.append((instance_idx, label_idx))\n",
    "\n",
    "        \n",
    "# Step 2: Output the indices with single class in y_test\n",
    "# print(\"Instance and label indices where only one class is present in y_test:\")\n",
    "# for idx in single_class_indices:\n",
    "#     print(f\"Instance {idx[0]}, Label {idx[1]} has only class {y_test[idx[0], idx[1]]} present.\")\n",
    "#     break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
