{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14055da-3152-404b-a20d-426a3f7360d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99fcce54-67cb-4c43-bccf-2757c0fd3c42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 43992, 'test': 39554, 'covered_notes': 77}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(\"dataset/single_fold.json\") as f:\n",
    "    split_data = json.load(f)\n",
    "{k:len(v) for k, v in split_data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66bb801a-e9b3-49a6-b73f-f82705b9225d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import analysis.fingerprint\n",
    "\n",
    "mfpgen = analysis.fingerprint.make_mfpgen(radius=2,fpSize=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da0248dc-776f-4e0b-a017-ce476ca66c96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1471, 1468)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mols = set()\n",
    "for d in split_data[\"train\"]:\n",
    "    train_mols.update(d[\"edge\"])\n",
    "\n",
    "test_mols = set()\n",
    "for d in split_data[\"test\"]:\n",
    "    test_mols.update(d[\"edge\"])\n",
    "\n",
    "len(train_mols), len(test_mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2f3cda3-2e42-4354-bd65-14c54ffe9f8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b92ec7eb2a064b61af8942948890a8e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2939 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InChI=1/C7H8S/c1-6-4-2-3-5-7(6)8/h2-5,8H,1H3\n",
      "(C)C1=CN=CC(=N1)OC.CC(C)C1=CN=C(C=N1)OC.CC(C)C1=NC=CN=C1OC\n",
      "CC(=O)c1ccc(C)n1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:35:40] SMILES Parse Error: syntax error while parsing: InChI=1/C7H8S/c1-6-4-2-3-5-7(6)8/h2-5,8H,1H3\n",
      "[17:35:40] SMILES Parse Error: Failed parsing SMILES 'InChI=1/C7H8S/c1-6-4-2-3-5-7(6)8/h2-5,8H,1H3' for input: 'InChI=1/C7H8S/c1-6-4-2-3-5-7(6)8/h2-5,8H,1H3'\n",
      "[17:35:40] SMILES Parse Error: syntax error while parsing: (C)C1=CN=CC(=N1)OC.CC(C)C1=CN=C(C=N1)OC.CC(C)C1=NC=CN=C1OC\n",
      "[17:35:40] SMILES Parse Error: Failed parsing SMILES '(C)C1=CN=CC(=N1)OC.CC(C)C1=CN=C(C=N1)OC.CC(C)C1=NC=CN=C1OC' for input: '(C)C1=CN=CC(=N1)OC.CC(C)C1=CN=C(C=N1)OC.CC(C)C1=NC=CN=C1OC'\n",
      "[17:35:40] Can't kekulize mol.  Unkekulized atoms: 3 4 5 6 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('C=CCOC(=O)CCCC1CCCCC1', array([0, 0, 1, ..., 0, 0, 0], dtype=uint8))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "mol_to_embed = dict()\n",
    "for m in tqdm(train_mols.union(test_mols)):\n",
    "    try:\n",
    "        mol_to_embed[m] = analysis.fingerprint.smiles_to_embed(mfpgen,m)\n",
    "    except Exception as e:\n",
    "        print(m)\n",
    "        continue\n",
    "        \n",
    "    \n",
    "next(iter(mol_to_embed.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "745299d6-cb4d-45d8-b671-98efc618a80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_blend_notes = {'oily', 'ethereal', 'fermented', 'bitter', 'soapy', 'phenolic', 'winey', 'roasted', 'spicy', 'fusel', 'tropical', 'anise', 'honey', 'aromatic', 'meaty', 'fresh', 'woody', 'melon', 'mentholic', 'clean', 'camphoreous', 'nutty', 'herbal', 'jammy', 'earthy', 'vegetable', 'caramellic', 'coconut', 'orris', 'bready', 'citrus', 'chemical', 'burnt', 'dairy', 'cheesy', 'fatty', 'floral', 'fruity', 'green', 'marine', 'coumarinic', 'licorice', 'mossy', 'tonka', 'creamy', 'waxy', 'animal', 'acidic', 'brown', 'cocoa', 'chocolate', 'sweet', 'rummy', 'sour', 'balsamic', 'coffee', 'solvent', 'fungal', 'berry', 'amber', 'cooling', 'onion', 'buttery', 'estery', 'powdery', 'musk', 'aldehydic', 'medicinal', 'alliaceous', 'minty', 'vanilla', 'thujonic', 'sulfurous', 'musty'}\n",
    "all_blend_notes = list(all_blend_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b12b3cf-de32-4219-9e14-eb967a4c5d87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc3397180451499fa2d0aee23903c330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43992 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 262 empty blends.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce3bdf4a1ac48f6be56c3dd951d1f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39554 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 286 empty blends.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((43721, 2048), (39237, 2048), (43721, 74), (39237, 74))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import graph.utils\n",
    "\n",
    "def make_notes_vectors(dataset,should_concat=True):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    empty = 0\n",
    "    for d in tqdm(dataset):\n",
    "        blnd = graph.utils.canonize(d[\"blend_notes\"])\n",
    "        \n",
    "        mol1, mol2 = d[\"edge\"]\n",
    "        if not mol1 in mol_to_embed or not mol2 in mol_to_embed:\n",
    "            continue\n",
    "        \n",
    "        if should_concat:\n",
    "            x = np.concatenate([mol_to_embed[mol1],mol_to_embed[mol2]])\n",
    "        else:\n",
    "            x = mol_to_embed[mol1] + mol_to_embed[mol2]\n",
    "        y = graph.utils.multi_hot(blnd,all_blend_notes)\n",
    "\n",
    "        if x.sum() == 0 or y.sum() == 0:\n",
    "            empty += 1\n",
    "            continue\n",
    "\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        \n",
    "    print(f\"Found {empty} empty blends.\")        \n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "train_x, train_y = make_notes_vectors(split_data[\"train\"])\n",
    "test_x, test_y = make_notes_vectors(split_data[\"test\"])\n",
    "train_x.shape, test_x.shape, train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0937bba2-f67d-433f-80c1-d057afe9a5fa",
   "metadata": {},
   "source": [
    "### Using concatenation of MFPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42e315d5-8105-4c59-9d00-e94cd793c84b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data looks good!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def checksum(vector):\n",
    "    # Assert every label has a sample and Assert every sample has a label\n",
    "    return (vector.sum(axis=0) > 0).all() and (vector.sum(axis=1) > 0).all()\n",
    "assert checksum(train_y)\n",
    "assert checksum(test_y)\n",
    "\"Data looks good!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79f5f65e-b140-4773-b222-a382d73c2f75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Training the model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84121359894342a3b9b7aa6ca1a134cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training classifiers for each label:   0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting probabilities for AUROC calculation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8615f0069ea49d3b6b3095b3af0c4af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting probabilities:   0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-averaged AUROC: 0.9099210985253112\n",
      "Macro-averaged AUROC: 0.7390302686437905\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "import sklearn.ensemble\n",
    "import sklearn.linear_model\n",
    "\n",
    "def train_evaluate_model(base_classifier):\n",
    "    print(\"Training the model...\")\n",
    "    # Hack because I want progress bars\n",
    "    estimators = []\n",
    "    for i in tqdm(range(train_y.shape[1]), desc=\"Training classifiers for each label\"):\n",
    "        classifier = sklearn.base.clone(base_classifier) \n",
    "        estimators.append(classifier.fit(train_x, train_y[:, i]))\n",
    "        \n",
    "    print(\"Predicting probabilities for AUROC calculation...\")\n",
    "    test_pred = np.zeros_like(test_y, dtype=float)\n",
    "    for i in tqdm(range(test_y.shape[1]), desc=\"Predicting probabilities\"):\n",
    "        test_pred[:, i] = estimators[i].predict_proba(test_x)[:,1]\n",
    "    \n",
    "    # Calculate AUROC for micro and macro averaging\n",
    "    auc_micro = sklearn.metrics.roc_auc_score(test_y, test_pred, average='micro')\n",
    "    auc_macro = sklearn.metrics.roc_auc_score(test_y, test_pred, average='macro')\n",
    "\n",
    "    print(\"Micro-averaged AUROC:\", auc_micro)\n",
    "    print(\"Macro-averaged AUROC:\", auc_macro)\n",
    "    \n",
    "print(\"Logistic Regression\")\n",
    "train_evaluate_model(sklearn.linear_model.LogisticRegression(max_iter=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a789ee-a353-4880-b2b1-91b43e7cbbc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Training the model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19beca54fd8f4aa2a32fe64986673c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training classifiers for each label:   0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn.ensemble\n",
    "\n",
    "print(\"Random Forest\")\n",
    "train_evaluate_model(sklearn.ensemble.RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da2da0b-745b-4d77-ba12-59fe64a35173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sklearn.svm\n",
    "import sklearn.multioutput\n",
    "\n",
    "print(\"SVM\")\n",
    "train_evaluate_model(sklearn.svm.SVC(probability=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc8625a-6c53-4acb-9a51-9f2846d082a5",
   "metadata": {},
   "source": [
    "### Using summation of MFPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7569b64d-4bd6-4786-8fc0-2bab9b9c980d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_x, train_y = make_notes_vectors(split_data[\"train\"],split_data[\"covered_notes\"],should_concat=False)\n",
    "test_x, test_y = make_notes_vectors(split_data[\"test\"],split_data[\"covered_notes\"],should_concat=False)\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)\n",
    "assert checksum(train_y)\n",
    "assert checksum(test_y)\n",
    "\"Data looks good!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52c5f71-b7dd-49a6-918b-2079d12c426c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Logistic Regression\")\n",
    "train_evaluate_model(sklearn.linear_model.LinearRegression())\n",
    "print()\n",
    "print(\"Random Forest\")\n",
    "train_evaluate_model(sklearn.ensemble.RandomForestClassifier())\n",
    "print()\n",
    "print(\"SVM\")\n",
    "train_evaluate_model(sklearn.svm.SVC(probability=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
