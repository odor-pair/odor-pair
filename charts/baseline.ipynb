{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d14055da-3152-404b-a20d-426a3f7360d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/laurasisson/odor-pair'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99fcce54-67cb-4c43-bccf-2757c0fd3c42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 43992, 'test': 39554, 'covered_notes': 77}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(\"dataset/single_fold.json\") as f:\n",
    "    split_data = json.load(f)\n",
    "{k:len(v) for k, v in split_data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66bb801a-e9b3-49a6-b73f-f82705b9225d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import analysis.fingerprint\n",
    "\n",
    "mfpgen = analysis.fingerprint.make_mfpgen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da0248dc-776f-4e0b-a017-ce476ca66c96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1471, 1468)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mols = set()\n",
    "for d in split_data[\"train\"]:\n",
    "    train_mols.update(d[\"edge\"])\n",
    "\n",
    "test_mols = set()\n",
    "for d in split_data[\"test\"]:\n",
    "    test_mols.update(d[\"edge\"])\n",
    "\n",
    "len(train_mols), len(test_mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2f3cda3-2e42-4354-bd65-14c54ffe9f8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d3411ffb9aa4b03ac0a8d5527d519ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2939 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(C)C1=CN=CC(=N1)OC.CC(C)C1=CN=C(C=N1)OC.CC(C)C1=NC=CN=C1OC\n",
      "InChI=1/C7H8S/c1-6-4-2-3-5-7(6)8/h2-5,8H,1H3\n",
      "CC(=O)c1ccc(C)n1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18:35:25] SMILES Parse Error: syntax error while parsing: (C)C1=CN=CC(=N1)OC.CC(C)C1=CN=C(C=N1)OC.CC(C)C1=NC=CN=C1OC\n",
      "[18:35:25] SMILES Parse Error: Failed parsing SMILES '(C)C1=CN=CC(=N1)OC.CC(C)C1=CN=C(C=N1)OC.CC(C)C1=NC=CN=C1OC' for input: '(C)C1=CN=CC(=N1)OC.CC(C)C1=CN=C(C=N1)OC.CC(C)C1=NC=CN=C1OC'\n",
      "[18:35:25] SMILES Parse Error: syntax error while parsing: InChI=1/C7H8S/c1-6-4-2-3-5-7(6)8/h2-5,8H,1H3\n",
      "[18:35:25] SMILES Parse Error: Failed parsing SMILES 'InChI=1/C7H8S/c1-6-4-2-3-5-7(6)8/h2-5,8H,1H3' for input: 'InChI=1/C7H8S/c1-6-4-2-3-5-7(6)8/h2-5,8H,1H3'\n",
      "[18:35:25] Can't kekulize mol.  Unkekulized atoms: 3 4 5 6 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('CCC(C)C(=O)OC\\\\C=C(/C)\\\\CCC=C(C)C',\n",
       " array([0, 1, 0, ..., 0, 0, 0], dtype=uint8))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "mol_to_embed = dict()\n",
    "for m in tqdm(train_mols.union(test_mols)):\n",
    "    try:\n",
    "        mol_to_embed[m] = analysis.fingerprint.smiles_to_embed(mfpgen,m)\n",
    "    except Exception as e:\n",
    "        print(m)\n",
    "        continue\n",
    "        \n",
    "    \n",
    "next(iter(mol_to_embed.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "745299d6-cb4d-45d8-b671-98efc618a80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_blend_notes = {'oily', 'ethereal', 'fermented', 'bitter', 'soapy', 'phenolic', 'winey', 'roasted', 'spicy', 'fusel', 'tropical', 'anise', 'honey', 'aromatic', 'meaty', 'fresh', 'woody', 'melon', 'mentholic', 'clean', 'camphoreous', 'nutty', 'herbal', 'jammy', 'earthy', 'vegetable', 'caramellic', 'coconut', 'orris', 'bready', 'citrus', 'chemical', 'burnt', 'dairy', 'cheesy', 'fatty', 'floral', 'fruity', 'green', 'marine', 'coumarinic', 'licorice', 'mossy', 'tonka', 'creamy', 'waxy', 'animal', 'acidic', 'brown', 'cocoa', 'chocolate', 'sweet', 'rummy', 'sour', 'balsamic', 'coffee', 'solvent', 'fungal', 'berry', 'amber', 'cooling', 'onion', 'buttery', 'estery', 'powdery', 'musk', 'aldehydic', 'medicinal', 'alliaceous', 'minty', 'vanilla', 'thujonic', 'sulfurous', 'musty'}\n",
    "all_blend_notes = list(all_blend_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b12b3cf-de32-4219-9e14-eb967a4c5d87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7239b4404f6d4ad5a085d598394a1632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43992 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 262 empty blends.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b17e1a00a1452ea22d1c5c16466490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39554 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 286 empty blends.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((500, 4096), (39237, 4096), (500, 74), (39237, 74))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import graph.utils\n",
    "\n",
    "def make_notes_vectors(dataset,should_concat=True):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    empty = 0\n",
    "    for d in tqdm(dataset):\n",
    "        blnd = graph.utils.canonize(d[\"blend_notes\"])\n",
    "        \n",
    "        mol1, mol2 = d[\"edge\"]\n",
    "        if not mol1 in mol_to_embed or not mol2 in mol_to_embed:\n",
    "            continue\n",
    "        \n",
    "        if should_concat:\n",
    "            x = np.concatenate([mol_to_embed[mol1],mol_to_embed[mol2]])\n",
    "        else:\n",
    "            x = mol_to_embed[mol1] + mol_to_embed[mol2]\n",
    "        y = graph.utils.multi_hot(blnd,all_blend_notes)\n",
    "\n",
    "        if x.sum() == 0 or y.sum() == 0:\n",
    "            empty += 1\n",
    "            continue\n",
    "\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        \n",
    "    print(f\"Found {empty} empty blends.\")        \n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "train_x, train_y = make_notes_vectors(split_data[\"train\"])\n",
    "test_x, test_y = make_notes_vectors(split_data[\"test\"])\n",
    "train_x, train_y = train_x[:500], train_y[:500]\n",
    "train_x.shape, test_x.shape, train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0937bba2-f67d-433f-80c1-d057afe9a5fa",
   "metadata": {},
   "source": [
    "### Using concatenation of MFPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42e315d5-8105-4c59-9d00-e94cd793c84b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def checksum(vector):\n",
    "#     # Assert every label has a sample and Assert every sample has a label\n",
    "#     return (vector.sum(axis=0) > 0).all() and (vector.sum(axis=1) > 0).all()\n",
    "# assert checksum(train_y)\n",
    "# assert checksum(test_y)\n",
    "# \"Data looks good!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bac83305-8cf3-4471-82db-b0189b29c8b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "micro_auroc = torchmetrics.classification.MultilabelAUROC(len(all_blend_notes),average=\"micro\")\n",
    "macro_auroc = torchmetrics.classification.MultilabelAUROC(len(all_blend_notes),average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79f5f65e-b140-4773-b222-a382d73c2f75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Predicting probabilities for AUROC calculation...\n",
      "Micro-averaged AUROC: tensor(0.5982)\n",
      "Macro-averaged AUROC: tensor(0.6157)\n",
      "Micro-averaged AUROC: 0.5981247783667468\n",
      "Macro-averaged AUROC: 0.6156553440342918\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "\n",
    "class LogitRegression:\n",
    "    EPS = 1e-5\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def _clip01(self, arr):\n",
    "        return np.asarray(arr).clip(self.EPS, 1 - self.EPS)\n",
    "\n",
    "    def fit(self, x, p):\n",
    "        p = self._clip01(p)\n",
    "        y = scipy.special.logit(p)\n",
    "        return self.model.fit(x, y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        y = self.model.predict(x)\n",
    "        return scipy.special.expit(y)\n",
    "\n",
    "def train_evaluate_model(base_classifier):\n",
    "    print(\"Training the model...\")\n",
    "    model = LogitRegression(base_classifier)\n",
    "    model.fit(train_x,train_y)\n",
    "    \n",
    "    print(\"Predicting probabilities for AUROC calculation...\")\n",
    "    test_pred = model.predict(test_x)\n",
    "    \n",
    "    # Calculate AUROC for micro and macro averaging\n",
    "    auc_micro = micro_auroc(torch.from_numpy(test_pred).float(), torch.from_numpy(test_y).int())\n",
    "    auc_macro = macro_auroc(torch.from_numpy(test_pred).float(), torch.from_numpy(test_y).int())\n",
    "\n",
    "    print(\"Micro-averaged AUROC:\", auc_micro)\n",
    "    print(\"Macro-averaged AUROC:\", auc_macro)\n",
    "    \n",
    "    # Calculate AUROC for micro and macro averaging\n",
    "    auc_micro = sklearn.metrics.roc_auc_score(test_y, test_pred, average='micro')\n",
    "    auc_macro = sklearn.metrics.roc_auc_score(test_y, test_pred, average='macro')\n",
    "\n",
    "    print(\"Micro-averaged AUROC:\", auc_micro)\n",
    "    print(\"Macro-averaged AUROC:\", auc_macro)\n",
    "\n",
    "train_evaluate_model(sklearn.linear_model.LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53a789ee-a353-4880-b2b1-91b43e7cbbc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Training the model...\n",
      "Predicting probabilities for AUROC calculation...\n",
      "Micro-averaged AUROC: tensor(0.8890)\n",
      "Macro-averaged AUROC: tensor(0.6339)\n",
      "Micro-averaged AUROC: 0.8889672824742723\n",
      "Macro-averaged AUROC: 0.6338825922902375\n"
     ]
    }
   ],
   "source": [
    "import sklearn.ensemble\n",
    "\n",
    "print(\"Random Forest\")\n",
    "train_evaluate_model(sklearn.ensemble.RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da2da0b-745b-4d77-ba12-59fe64a35173",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "Training the model...\n",
      "Predicting probabilities for AUROC calculation...\n"
     ]
    }
   ],
   "source": [
    "import sklearn.svm\n",
    "import sklearn.multioutput\n",
    "\n",
    "print(\"SVM\")\n",
    "train_evaluate_model(sklearn.multioutput.MultiOutputRegressor(sklearn.svm.SVR()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc8625a-6c53-4acb-9a51-9f2846d082a5",
   "metadata": {},
   "source": [
    "### Using summation of MFPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7569b64d-4bd6-4786-8fc0-2bab9b9c980d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_x, train_y = make_notes_vectors(split_data[\"train\"],split_data[\"covered_notes\"],should_concat=False)\n",
    "test_x, test_y = make_notes_vectors(split_data[\"test\"],split_data[\"covered_notes\"],should_concat=False)\n",
    "train_x, train_y = train_x[:500], train_y[:500]\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)\n",
    "# assert checksum(train_y)\n",
    "# assert checksum(test_y)\n",
    "\"Data looks good!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52c5f71-b7dd-49a6-918b-2079d12c426c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Logistic Regression\")\n",
    "train_evaluate_model(sklearn.linear_model.LinearRegression())\n",
    "print()\n",
    "print(\"Random Forest\")\n",
    "train_evaluate_model(sklearn.ensemble.RandomForestRegressor())\n",
    "print()\n",
    "print(\"SVM\")\n",
    "train_evaluate_model(sklearn.multioutput.MultiOutputRegressor(sklearn.svm.SVR()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
