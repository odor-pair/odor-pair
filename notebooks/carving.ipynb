{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4357a74-0bbf-4c97-bf16-aa291eb1acaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/laurasisson/odor-pair'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ae5be2e-aeac-429d-aeec-7a24679d544a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266721,\n",
       " {'mol1': 'CCCC(CC)O',\n",
       "  'mol2': 'CC1=CC2C(C2(C)C)CC1C(=O)C',\n",
       "  'blend_notes': ['herbal']})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(\"dataset/aroma_large.json\",\"r\") as f:\n",
    "    data = json.load(f)\n",
    "len(data), data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9119eb0d-6376-4801-95ec-2d0bb383eff4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "import graph.utils\n",
    "\n",
    "all_edges = set()\n",
    "all_nodes = set()\n",
    "edge_to_notes = dict()\n",
    "node_to_edges = collections.defaultdict(set)\n",
    "all_notes = set()\n",
    "\n",
    "\n",
    "for d in data:\n",
    "    edge = graph.utils.sort(d[\"mol1\"],d[\"mol2\"])\n",
    "    all_edges.add(edge)\n",
    "    edge_to_notes[edge] = d[\"blend_notes\"]\n",
    "    all_notes.update(d[\"blend_notes\"])\n",
    "\n",
    "\n",
    "    all_nodes.add(d[\"mol1\"])\n",
    "    node_to_edges[d[\"mol1\"]].add(edge)\n",
    "    \n",
    "    all_nodes.add(d[\"mol2\"])\n",
    "    node_to_edges[d[\"mol2\"]].add(edge)\n",
    "\n",
    "\n",
    "for n1, n2 in all_edges:\n",
    "    if (n2,n1) in all_edges:\n",
    "        print(n2,n2)\n",
    "    assert not (n2,n1) in all_edges\n",
    "    assert not n1 == n2\n",
    "\n",
    "full_graph = collections.defaultdict(set)\n",
    "for n1, n2 in all_edges:\n",
    "    full_graph[n1].add(n2)\n",
    "    full_graph[n2].add(n1)\n",
    "\n",
    "train_fraction = .8\n",
    "test_fraction = .2\n",
    "\n",
    "assert train_fraction + test_fraction == 1\n",
    "len(all_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "907dd0bc-dc89-4728-998e-e6e4c17456a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('CCCCCCCCCCCCOC(=O)CCC', 'CC(C)COC(=O)CCCCCCCCC=C')}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def build_edges(subgraph_nodes):\n",
    "    subgraph_edges = set()\n",
    "    for node in subgraph_nodes:\n",
    "        for other in full_graph[node]:\n",
    "            if not other in subgraph_nodes:\n",
    "                continue\n",
    "            subgraph_edges.add(graph.utils.sort(node,other))\n",
    "    return subgraph_edges\n",
    "build_edges(random.sample(list(all_nodes),10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b2e7cf-494f-4245-9eb3-d88c0236761e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173564 9916 102 183480\n",
      "168708 11138 101 183480\n",
      "172783 10169 102 183480\n",
      "169192 11227 102 183480\n",
      "173722 9901 102 183623\n",
      "172228 10310 102 183623\n",
      "169667 10842 102 183623\n",
      "175459 9612 102 185071\n",
      "169959 10598 102 185071\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def anneal_better_coverage(lim=100):\n",
    "    def build_covered(edges):\n",
    "        covered = collections.Counter()\n",
    "        for e in edges:\n",
    "            covered.update(edge_to_notes[e])\n",
    "        return covered\n",
    "\n",
    "    def get_data(nodes):\n",
    "        edges = build_edges(nodes)\n",
    "        return nodes, edges, build_covered(edges)\n",
    "\n",
    "    def get_relevant_edges(new_nodes,n):\n",
    "        edges = node_to_edges[n]\n",
    "        return {(n1,n2) for (n1,n2) in edges if n1 in new_nodes and n2 in new_nodes}\n",
    "\n",
    "    def update_data(nodes,edges,covered,to_add,to_remove):\n",
    "        remove_edges = get_relevant_edges(nodes,to_remove)\n",
    "        new_nodes = {n for n in nodes if n!=to_remove}\n",
    "\n",
    "        new_nodes.add(to_add)\n",
    "        add_edges = get_relevant_edges(new_nodes,to_add)\n",
    "\n",
    "        lost = build_covered(remove_edges)\n",
    "        gained = build_covered(add_edges)\n",
    "\n",
    "        new_edges = edges.union(add_edges).difference(remove_edges)\n",
    "        new_covered = covered - lost + gained\n",
    "        return new_nodes, new_edges, new_covered\n",
    "\n",
    "    all_covered = set()\n",
    "    i = 0\n",
    "    train_nodes = set(random.sample(sorted(all_nodes),int(len(all_nodes)*train_fraction)))\n",
    "    test_nodes = all_nodes.difference(train_nodes)\n",
    "    \n",
    "    train_nodes, train_edges, train_covered = get_data(train_nodes)\n",
    "    test_nodes, test_edges, test_covered = get_data(test_nodes)\n",
    "\n",
    "    skip_bad_edge_trade = True\n",
    "\n",
    "    skipped = 0\n",
    "    hits = 0\n",
    "    with tqdm(total=lim,disable=True) as pbar:\n",
    "        while i < lim:\n",
    "            fraction = i/lim\n",
    "            covered = set(train_covered.keys()).intersection(set(test_covered.keys()))\n",
    "            old_covered = len(covered)\n",
    "            # if i % int(lim*.1) == 0:\n",
    "            #     print(\"Swap\",fraction,f\"{skipped/(hits+1):.2f}\",len(train_edges),len(test_edges),(len(train_edges)+len(test_edges))/len(all_edges))\n",
    "            # elif i % int(lim*.01) == 0:\n",
    "            #     print(\"Swap\",i,len(train_covered),len(test_covered),len(set(train_covered.keys()).intersection(set(test_covered.keys()))))\n",
    "            # if i % int(lim*.05) == 0:\n",
    "            #     print(\"MISSING\",sorted(list(graph.utils.missing_notes(covered))))\n",
    "\n",
    "            i += 1\n",
    "            x1,x2 = random.choice(list(train_nodes)), random.choice(list(test_nodes))\n",
    "            new_train_nodes, new_train_edges, new_train_covered = update_data(train_nodes,train_edges,train_covered,x2,x1)\n",
    "            new_test_nodes, new_test_edges, new_test_covered = update_data(test_nodes,test_edges,test_covered,x1,x2)\n",
    "\n",
    "            new_covered = len(set(new_train_covered.keys()).intersection(set(new_test_covered.keys())))\n",
    "\n",
    "            if new_covered < old_covered:\n",
    "                skipped += 1\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "\n",
    "            if len(new_train_covered) < len(train_covered) or len(new_test_covered) < len(test_covered):\n",
    "                skipped += 1\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "\n",
    "            # As the fraction approaches 1, this statement becomes true more,\n",
    "            # So we skip bad trades more.\n",
    "            #  \n",
    "            # if random.random()/100 < fraction and (len(new_train_edges) < len(train_edges) or len(new_test_edges) < len(test_edges)):\n",
    "            #     skipped += 1\n",
    "            #     pbar.update(1)\n",
    "            #     continue\n",
    "\n",
    "            train_nodes, train_edges, train_covered = new_train_nodes, new_train_edges, new_train_covered\n",
    "            test_nodes, test_edges, test_covered = new_test_nodes, new_test_edges, new_test_covered\n",
    "            hits += 1\n",
    "            pbar.update(1)\n",
    "            \n",
    "        \n",
    "\n",
    "    train_covered_set = {k for k,v in train_covered.most_common() if v>0}\n",
    "    test_covered_set = {k for k,v in test_covered.most_common() if v>0}\n",
    "    covered = list(train_covered_set.intersection(test_covered_set))\n",
    "    return train_edges, test_edges, covered\n",
    "\n",
    "best_total = 0\n",
    "for i in range(500):\n",
    "    train_edges, test_edges, covered = anneal_better_coverage(10000)\n",
    "    best_total = max(best_total, len(train_edges) + len(test_edges))\n",
    "    print(len(train_edges), len(test_edges), len(covered), best_total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
